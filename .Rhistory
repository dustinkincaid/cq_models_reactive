e8_nFit = e8_nFit
)
}
### Define possibly model
possibly_cv_mods_c0 = possibly(.f = cv_mods_c0, otherwise = NULL)
## Create list of datasets/dataset lists ----
df_list_cv1 <- list(df_grab %>% mutate(df = "lt_grab"),
df_15min %>% mutate(df = "15min"))
df_list_cv2 <- list(df_15min_daily_list,
df_15min_weekly_list,
df_15min_monthly_list)
## Do cross-validation ----
# This method assumes that the time series data are sorted by timestamp ahead of time
# Helpful websites:
# https://www.tidymodels.org/learn/models/time-series/
# https://rsample.tidymodels.org/reference/rolling_origin.html
# https://www.tmwr.org/resampling#rolling
# https://openforecast.org/adam/rollingOrigin.html
### DF_GRAB AND DF_15MIN ----
# USE THIS FOR df_grab AND df_15min (i.e., the dfs where we use all the data and don't do 10 versions of each)
#### First time with one c0 value ----
# Set c0
c0_set <- c0_bf
out1_c0_1 <- tibble()
for(i in 1:length(df_list_cv1)) {
# Run cross-validation
doParallel::registerDoParallel()
# Split smaller grab sample df slightly differently than 15-min data set
if(df_list_cv1[[i]]$df[[1]] == "lt_grab"){
# Set sample sizes of analysis and assessment splits;
# We will make the minimum sample size for analysis = 20
initial_n = ceiling(nrow(df_list_cv1[[i]])/2)
if(initial_n < 20){
intial_n = 20
}
assess_n = ceiling(initial_n/3)
skip_n = 1
# Create splits
splits <- rsample::rolling_origin(df_list_cv1[[i]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id)
# Split larger 15-min dataset
} else {
# 1 day = 24 * 60 / 15 = 96 rows
# 14 days = 96 * 14 = 1344
# 30 days = 96 * 30 = 2880
# 3 months-ish or 300 days = 2880 * 3
initial_n = ceiling(nrow(df_list_cv1[[i]])/2)
assess_n = ceiling(initial_n/3)
skip_n = 2880
splits <- rsample::rolling_origin(df_list_cv1[[i]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id)
}
# Estimate the cv on all splits
out <-
splits %>%
mutate(err = map(splits,
possibly_cv_mods)) %>%
# Remove models with errors (typically singular gradient errors)
compact() %>%
## drop the splits column (THIS WAS NECESSARY FOR THE LARGER DATASETS; OTHERWISE CODE GOT STUCK HERE)
select(-splits)
# Unnest err column in out (I separated this function for larger datasets that get hung up in previous step)
out_unnest <-
out %>%
unnest(err)
# Get the average cross-validation error for each model:
out2 <-
out_unnest %>%
group_by(id) %>%
## sum up the sums of squared errors across partitions
summarise(across(e0:e8_nFit, ~sd(.x))) %>%
## calculate average CV error:
# summarise(across(e1:e2, ~mean(.x)))
pivot_longer(cols = e0:e8_nFit, names_to = "eq", values_to = "sse") %>%
full_join(maxmin_c, by = join_by(id)) %>%
mutate(n_sse = sse/(max_c - min_c)) %>%
group_by(eq) %>%
summarize(rmse_mean = mean(sse),
rmse_n = n(),
rmse_sd = sd(sse),
rmse_se = rmse_sd/sqrt(rmse_n),
nrmse_mean = mean(n_sse),
nrmse_sd = sd(n_sse),
nrmse_se = nrmse_sd/sqrt(rmse_n)) %>%
mutate(alpha = 0.05,
deg_fr = rmse_n - 1,
t_score = qt(p = alpha/2, df = deg_fr, lower.tail = F),
margin_err = t_score * rmse_se,
rmse_ci_lower = rmse_mean - margin_err,
rmse_ci_upper = rmse_mean + margin_err,
nrmse_ci_lower = nrmse_mean - margin_err,
nrmse_ci_upper = nrmse_mean + margin_err) %>%
mutate(df = as.character(df_list_cv1[[i]][1, "df"]),
c0_source = "baseflow",
c0_value = c0_set)
# Aggregate the outputs
out1_c0_1 <- bind_rows(out1_c0_1, out2)
}
#### Second time with second c0 value ----
# Set c0
c0_set <- c0_wd
out1_c0_2 <- tibble()
for(i in 1:length(df_list_cv1)) {
# Run cross-validation
doParallel::registerDoParallel()
# Split smaller grab sample df slightly differently than 15-min data set
if(df_list_cv1[[i]]$df[[1]] == "lt_grab"){
# Set sample sizes of analysis and assessment splits;
# We will make the minimum sample size for analysis = 20
initial_n = ceiling(nrow(df_list_cv1[[i]])/2)
if(initial_n < 20){
intial_n = 20
}
assess_n = ceiling(initial_n/3)
skip_n = 1
# Create splits
splits <- rsample::rolling_origin(df_list_cv1[[i]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id)
# Split larger 15-min dataset
} else {
# 1 day = 24 * 60 / 15 = 96 rows
# 14 days = 96 * 14 = 1344
# 30 days = 96 * 30 = 2880
# 3 months-ish or 300 days = 2880 * 3
initial_n = ceiling(nrow(df_list_cv1[[i]])/2)
assess_n = ceiling(initial_n/3)
skip_n = 2880
splits <- rsample::rolling_origin(df_list_cv1[[i]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id)
}
# Estimate the cv on all splits
out <-
splits %>%
mutate(err = map(splits,
possibly_cv_mods_c0)) %>%
# Remove models with errors (typically singular gradient errors)
compact() %>%
## drop the splits column (THIS WAS NECESSARY FOR THE LARGER DATASETS; OTHERWISE CODE GOT STUCK HERE)
select(-splits)
# Unnest err column in out (I separated this function for larger datasets that get hung up in previous step)
out_unnest <-
out %>%
unnest(err)
# Get the average cross-validation error for each model:
out2 <-
out_unnest %>%
group_by(id) %>%
## sum up the sums of squared errors across partitions
summarise(across(e2:e8_nFit, ~sd(.x))) %>%
## calculate average CV error:
# summarise(across(e1:e2, ~mean(.x)))
pivot_longer(cols = e2:e8_nFit, names_to = "eq", values_to = "sse") %>%
full_join(maxmin_c, by = join_by(id)) %>%
mutate(n_sse = sse/(max_c - min_c)) %>%
group_by(eq) %>%
summarize(rmse_mean = mean(sse),
rmse_n = n(),
rmse_sd = sd(sse),
rmse_se = rmse_sd/sqrt(rmse_n),
nrmse_mean = mean(n_sse),
nrmse_sd = sd(n_sse),
nrmse_se = nrmse_sd/sqrt(rmse_n)) %>%
mutate(alpha = 0.05,
deg_fr = rmse_n - 1,
t_score = qt(p = alpha/2, df = deg_fr, lower.tail = F),
margin_err = t_score * rmse_se,
rmse_ci_lower = rmse_mean - margin_err,
rmse_ci_upper = rmse_mean + margin_err,
nrmse_ci_lower = nrmse_mean - margin_err,
nrmse_ci_upper = nrmse_mean + margin_err) %>%
mutate(df = as.character(df_list_cv1[[i]][1, "df"]),
c0_source = "wet_deposition",
c0_value = c0_set)
# Aggregate the outputs
out1_c0_2 <- bind_rows(out1_c0_2, out2)
}
### REDUCED REPS OF THE 15-min DATA ----
# USE THIS FOR THE REDUCED REPS OF THE 15-min DATA (e.g., df_15min_daily, etc.)
#### First time with one c0 value ----
# Set c0
c0_set <- c0_bf
out2_c0_1 <- tibble()
for(i in 1:length(df_list_cv2)) {
# Run cross-validation
doParallel::registerDoParallel()
# Loop through the lists of dataframes
out_sub <- tibble()
maxmin_c_sub <- tibble()
for (j in 1:length(df_list_cv2[[i]])) {
# # Split larger daily sample df slightly differently than smaller dataset
if(df_list_cv2[[i]][[j]]$df[[1]] == "daily") {
# Set sample sizes of analysis and assessment splits;
# We will make the minimum sample size for analysis = 20
initial_n = ceiling(nrow(df_list_cv2[[i]][[j]])/2)
assess_n = ceiling(initial_n/3)
skip_n = 30
splits <- rsample::rolling_origin(df_list_cv2[[i]][[j]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id) %>%
mutate(df_rep = j)
# Split weekly datasets
} else if(df_list_cv2[[i]][[j]]$df[[1]] == "weekly"){
initial_n = ceiling(nrow(df_list_cv2[[i]][[j]])/2)
assess_n = ceiling(initial_n/3)
skip_n = 4
splits <- rsample::rolling_origin(df_list_cv2[[i]][[j]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id) %>%
mutate(df_rep = j)
# Split monthly datasets
} else {
initial_n = ceiling(nrow(df_list_cv2[[i]][[j]])/2)
if(initial_n < 20){
intial_n = 20
}
assess_n = ceiling(initial_n/3)
skip_n = 0
splits <- rsample::rolling_origin(df_list_cv2[[i]][[j]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id) %>%
mutate(df_rep = j)
}
out <-
splits %>%
## estimate the cv on all of the partitions
mutate(err = map(splits,
possibly_cv_mods)) %>%
# Remove models with errors (typically singular gradient errors)
compact() %>%
## drop the splits column (THIS WAS NECESSARY FOR THE LARGER DATASETS; OTHERWISE CODE GOT STUCK HERE)
select(-splits)
# Unnest err column in out (I separated this function for larger datasets that get hung up in previous step)
out_unnest <-
out %>%
unnest(err) %>%
mutate(df_rep = j)
out_sub <- bind_rows(out_sub, out_unnest)
maxmin_c_sub <- bind_rows(maxmin_c_sub, maxmin_c)
}
# get the average cross-validation error for each model:
out2 <-
out_sub %>%
group_by(df_rep, id) %>%
## sum up the sums of squared errors across partitions
summarise(across(e0:e8_nFit, ~sd(.x))) %>%
## calculate average CV error:
# summarise(across(e1:e2, ~mean(.x)))
pivot_longer(cols = e0:e8_nFit, names_to = "eq", values_to = "sse") %>%
full_join(maxmin_c_sub, by = join_by(df_rep, id)) %>%
mutate(n_sse = sse/(max_c - min_c)) %>%
group_by(df_rep, eq) %>%
summarize(rmse_mean = mean(sse),
rmse_n = n(),
rmse_sd = sd(sse),
rmse_se = rmse_sd/sqrt(rmse_n),
nrmse_mean = mean(n_sse),
nrmse_sd = sd(n_sse),
nrmse_se = nrmse_sd/sqrt(rmse_n)) %>%
mutate(alpha = 0.05,
deg_fr = rmse_n - 1,
t_score = qt(p = alpha/2, df = deg_fr, lower.tail = F),
margin_err = t_score * rmse_se,
rmse_ci_lower = rmse_mean - margin_err,
rmse_ci_upper = rmse_mean + margin_err,
nrmse_ci_lower = nrmse_mean - margin_err,
nrmse_ci_upper = nrmse_mean + margin_err) %>%
group_by(eq) %>%
summarize(rmse_mean_2 = mean(rmse_mean),
rmse_n_2 = n(),
rmse_sd_2 = sd(rmse_mean),
rmse_se_2 =  rmse_sd_2/sqrt(rmse_n_2),
nrmse_mean_2 = mean(nrmse_mean),
nrmse_sd_2 = sd(nrmse_mean),
nrmse_se_2 = nrmse_sd_2/sqrt(rmse_n_2)) %>%
mutate(alpha = 0.05,
deg_fr = rmse_n_2 - 1,
t_score = qt(p = alpha/2, df = deg_fr, lower.tail = F),
margin_err = t_score * rmse_se_2,
rmse_ci_lower = rmse_mean_2 - margin_err,
rmse_ci_upper = rmse_mean_2 + margin_err,
nrmse_ci_lower = nrmse_mean_2 - margin_err,
nrmse_ci_upper = nrmse_mean_2 + margin_err) %>%
rename(rmse_mean = rmse_mean_2,
rmse_n = rmse_n_2,
rmse_sd = rmse_sd_2,
rmse_se = rmse_se_2,
nrmse_mean = nrmse_mean_2,
nrmse_sd = nrmse_sd_2,
nrmse_se = nrmse_se_2) %>%
mutate(method = "reps_separate") %>%
mutate(df = as.character(df_list_cv2[[i]][[1]][1, "df"]),
c0_source = "baseflow",
c0_value = c0_set)
# Aggreate outputs
out2_c0_1 <- bind_rows(out2_c0_1, out2)
}
#### Second time with second c0 value ----
# Set c0
c0_set <- c0_wd
out2_c0_2 <- tibble()
for(i in 1:length(df_list_cv2)) {
# Loop through the lists of dataframes
out_sub <- tibble()
maxmin_c_sub <- tibble()
for (j in 1:length(df_list_cv2[[i]])) {
# Split larger daily sample df slightly differently than smaller dataset
if(df_list_cv2[[i]][[j]]$df[[1]] == "daily") {
# Set sample sizes of analysis and assessment splits;
# We will make the minimum sample size for analysis = 20
initial_n = ceiling(nrow(df_list_cv2[[i]][[j]])/2)
assess_n = ceiling(initial_n/3)
skip_n = 30
splits <- rsample::rolling_origin(df_list_cv2[[i]][[j]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id) %>%
mutate(df_rep = j)
# Split weekly datasets
} else if(df_list_cv2[[i]][[j]]$df[[1]] == "weekly"){
initial_n = ceiling(nrow(df_list_cv2[[i]][[j]])/2)
assess_n = ceiling(initial_n/3)
skip_n = 4
splits <- rsample::rolling_origin(df_list_cv2[[i]][[j]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id) %>%
mutate(df_rep = j)
# Split monthly datasets
} else {
initial_n = ceiling(nrow(df_list_cv2[[i]][[j]])/2)
if(initial_n < 20){
intial_n = 20
}
assess_n = ceiling(initial_n/3)
skip_n = 0
splits <- rsample::rolling_origin(df_list_cv2[[i]][[j]],
initial = initial_n,
assess = assess_n,
skip = skip_n)
# Pull min and max for each split for NRMSE later
maxmin_c <-
splits %>%
mutate(assessments = map(splits, assessment)) %>%
unnest(assessments) %>%
summarise(min_c = min(c),
max_c = max(c),
.by = id) %>%
mutate(df_rep = j)
}
out <-
splits %>%
## estimate the cv on all of the partitions
mutate(err = map(splits,
possibly_cv_mods_c0)) %>%
# Remove models with errors (typically singular gradient errors)
compact() %>%
## drop the splits column (THIS WAS NECESSARY FOR THE LARGER DATASETS; OTHERWISE CODE GOT STUCK HERE)
select(-splits)
# Unnest err column in out (I separated this function for larger datasets that get hung up in previous step)
out_unnest <-
out %>%
unnest(err) %>%
mutate(df_rep = j)
out_sub <- bind_rows(out_sub, out_unnest)
maxmin_c_sub <- bind_rows(maxmin_c_sub, maxmin_c)
}
# get the average cross-validation error for each model:
out2 <-
out_sub %>%
group_by(df_rep, id) %>%
## sum up the sums of squared errors across partitions
summarise(across(e2:e8_nFit, ~sd(.x))) %>%
## calculate average CV error:
# summarise(across(e1:e2, ~mean(.x)))
pivot_longer(cols = e2:e8_nFit, names_to = "eq", values_to = "sse") %>%
full_join(maxmin_c_sub, by = join_by(df_rep, id)) %>%
mutate(n_sse = sse/(max_c - min_c)) %>%
group_by(df_rep, eq) %>%
summarize(rmse_mean = mean(sse),
rmse_n = n(),
rmse_sd = sd(sse),
rmse_se = rmse_sd/sqrt(rmse_n),
nrmse_mean = mean(n_sse),
nrmse_sd = sd(n_sse),
nrmse_se = nrmse_sd/sqrt(rmse_n)) %>%
mutate(alpha = 0.05,
deg_fr = rmse_n - 1,
t_score = qt(p = alpha/2, df = deg_fr, lower.tail = F),
margin_err = t_score * rmse_se,
rmse_ci_lower = rmse_mean - margin_err,
rmse_ci_upper = rmse_mean + margin_err,
nrmse_ci_lower = nrmse_mean - margin_err,
nrmse_ci_upper = nrmse_mean + margin_err) %>%
group_by(eq) %>%
summarize(rmse_mean_2 = mean(rmse_mean),
rmse_n_2 = n(),
rmse_sd_2 = sd(rmse_mean),
rmse_se_2 =  rmse_sd_2/sqrt(rmse_n_2),
nrmse_mean_2 = mean(nrmse_mean),
nrmse_sd_2 = sd(nrmse_mean),
nrmse_se_2 = nrmse_sd_2/sqrt(rmse_n_2)) %>%
mutate(alpha = 0.05,
deg_fr = rmse_n_2 - 1,
t_score = qt(p = alpha/2, df = deg_fr, lower.tail = F),
margin_err = t_score * rmse_se_2,
rmse_ci_lower = rmse_mean_2 - margin_err,
rmse_ci_upper = rmse_mean_2 + margin_err,
nrmse_ci_lower = nrmse_mean_2 - margin_err,
nrmse_ci_upper = nrmse_mean_2 + margin_err) %>%
rename(rmse_mean = rmse_mean_2,
rmse_n = rmse_n_2,
rmse_sd = rmse_sd_2,
rmse_se = rmse_se_2,
nrmse_mean = nrmse_mean_2,
nrmse_sd = nrmse_sd_2,
nrmse_se = nrmse_se_2) %>%
mutate(method = "reps_separate") %>%
mutate(df = as.character(df_list_cv2[[i]][[1]][1, "df"]),
c0_source = "wet_deposition",
c0_value = c0_set)
# Aggreate outputs
out2_c0_2 <- bind_rows(out2_c0_2, out2)
}
#### Write to CSV for future use ----
out1_c0_1 %>%
bind_rows(out1_c0_2,
out2_c0_1,
out2_c0_2) %>%
write_csv(here("data", "out",  paste0("cq_all_cv", "_", sol_choice, "_", site_choice, ".csv")))
